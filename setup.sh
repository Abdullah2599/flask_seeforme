#!/bin/bash

# Advanced Multi-Dataset Object Detection System Setup Script
# Automated setup for the complete pipeline

set -e  # Exit on any error

echo "ðŸš€ Setting up Advanced Multi-Dataset Object Detection System"
echo "============================================================"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to print colored output
print_status() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_header() {
    echo -e "${BLUE}$1${NC}"
}

# Check if Python is installed
check_python() {
    print_header "Checking Python installation..."
    
    if command -v python3 &> /dev/null; then
        PYTHON_VERSION=$(python3 --version | cut -d' ' -f2)
        print_status "Python $PYTHON_VERSION found"
        
        # Check if version is 3.8+
        if python3 -c "import sys; exit(0 if sys.version_info >= (3, 8) else 1)"; then
            print_status "Python version is compatible (3.8+)"
        else
            print_error "Python 3.8+ is required. Please upgrade Python."
            exit 1
        fi
    else
        print_error "Python 3 is not installed. Please install Python 3.8+"
        exit 1
    fi
}

# Check if pip is installed
check_pip() {
    print_header "Checking pip installation..."
    
    if command -v pip3 &> /dev/null; then
        print_status "pip3 found"
    else
        print_error "pip3 is not installed. Please install pip3"
        exit 1
    fi
}

# Create virtual environment
create_venv() {
    print_header "Creating virtual environment..."
    
    if [ ! -d "venv" ]; then
        python3 -m venv venv
        print_status "Virtual environment created"
    else
        print_warning "Virtual environment already exists"
    fi
    
    # Activate virtual environment
    source venv/bin/activate
    print_status "Virtual environment activated"
}

# Install dependencies
install_dependencies() {
    print_header "Installing Python dependencies..."
    
    # Upgrade pip
    pip install --upgrade pip
    
    # Install PyTorch (CPU version for compatibility)
    print_status "Installing PyTorch..."
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
    
    # Install ultralytics (YOLOv8)
    print_status "Installing Ultralytics YOLOv8..."
    pip install ultralytics
    
    # Install Flask and web dependencies
    print_status "Installing Flask and web dependencies..."
    pip install flask pillow
    
    # Install data processing dependencies
    print_status "Installing data processing dependencies..."
    pip install pandas numpy matplotlib seaborn opencv-python
    
    # Install ML and evaluation dependencies
    print_status "Installing ML dependencies..."
    pip install scikit-learn tqdm pyyaml
    
    # Install web scraping dependencies
    print_status "Installing web scraping dependencies..."
    pip install requests selenium beautifulsoup4
    
    # Install CLIP and transformers for pseudo-labeling
    print_status "Installing CLIP and transformers..."
    pip install transformers clip-by-openai
    
    # Install system monitoring
    print_status "Installing system monitoring..."
    pip install psutil
    
    # Save requirements
    pip freeze > requirements.txt
    print_status "Requirements saved to requirements.txt"
}

# Create directory structure
create_directories() {
    print_header "Creating directory structure..."
    
    # Main directories
    mkdir -p datasets
    mkdir -p yolo_datasets
    mkdir -p merged_dataset
    mkdir -p models
    mkdir -p training_output
    mkdir -p evaluation_results
    mkdir -p regional_data/pakistan
    mkdir -p logs
    
    print_status "Directory structure created"
}

# Download initial models
download_models() {
    print_header "Downloading initial YOLOv8 models..."
    
    cd models
    
    # Download YOLOv8 models if not present
    if [ ! -f "yolov8n.pt" ]; then
        python3 -c "from ultralytics import YOLO; YOLO('yolov8n.pt')"
        print_status "YOLOv8n model downloaded"
    fi
    
    if [ ! -f "yolov8x.pt" ]; then
        python3 -c "from ultralytics import YOLO; YOLO('yolov8x.pt')"
        print_status "YOLOv8x model downloaded"
    fi
    
    cd ..
}

# Create configuration files
create_configs() {
    print_header "Creating configuration files..."
    
    # Create logging config
    cat > logging_config.yaml << EOF
version: 1
formatters:
  default:
    format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
handlers:
  console:
    class: logging.StreamHandler
    level: INFO
    formatter: default
    stream: ext://sys.stdout
  file:
    class: logging.FileHandler
    level: DEBUG
    formatter: default
    filename: logs/system.log
loggers:
  '':
    level: DEBUG
    handlers: [console, file]
EOF
    
    # Create environment config
    cat > .env << EOF
# Environment Configuration
FLASK_ENV=development
FLASK_DEBUG=True
MODEL_DIR=models
CACHE_SIZE=100
INFERENCE_TIMEOUT=30
MAX_IMAGE_SIZE=2048
MIN_CONFIDENCE=0.25
EOF
    
    print_status "Configuration files created"
}

# Setup git hooks (if git repo)
setup_git() {
    if [ -d ".git" ]; then
        print_header "Setting up git hooks..."
        
        # Create pre-commit hook
        cat > .git/hooks/pre-commit << 'EOF'
#!/bin/bash
# Pre-commit hook to run basic checks

echo "Running pre-commit checks..."

# Check Python syntax
find . -name "*.py" -not -path "./venv/*" | xargs python3 -m py_compile
if [ $? -ne 0 ]; then
    echo "Python syntax errors found!"
    exit 1
fi

echo "Pre-commit checks passed!"
EOF
        
        chmod +x .git/hooks/pre-commit
        print_status "Git hooks configured"
    fi
}

# Create startup scripts
create_startup_scripts() {
    print_header "Creating startup scripts..."
    
    # Flask development server script
    cat > start_flask_dev.sh << 'EOF'
#!/bin/bash
echo "ðŸš€ Starting Flask Development Server"
echo "===================================="

# Activate virtual environment
source venv/bin/activate

# Set environment variables
export FLASK_ENV=development
export FLASK_DEBUG=True

# Start Flask server
python app.py
EOF
    
    # Production server script
    cat > start_flask_prod.sh << 'EOF'
#!/bin/bash
echo "ðŸš€ Starting Flask Production Server"
echo "==================================="

# Activate virtual environment
source venv/bin/activate

# Set environment variables
export FLASK_ENV=production
export FLASK_DEBUG=False

# Start with gunicorn (install if needed)
if ! command -v gunicorn &> /dev/null; then
    pip install gunicorn
fi

gunicorn --bind 0.0.0.0:5000 --workers 4 app:app
EOF
    
    # Training pipeline script
    cat > run_training_pipeline.sh << 'EOF'
#!/bin/bash
echo "ðŸŽ¯ Starting Complete Training Pipeline"
echo "====================================="

# Activate virtual environment
source venv/bin/activate

# Step 1: Download datasets
echo "ðŸ“¥ Step 1: Downloading datasets..."
python data_pipeline/download_datasets.py

# Step 2: Convert to YOLO format
echo "ðŸ”„ Step 2: Converting datasets to YOLO format..."
python data_pipeline/convert_to_yolo.py

# Step 3: Merge datasets
echo "ðŸ”€ Step 3: Merging datasets..."
python data_pipeline/merge_datasets.py

# Step 4: Collect Pakistan data (optional)
echo "ðŸ‡µðŸ‡° Step 4: Collecting Pakistan-specific data..."
python regional_data/collect_pakistan_data.py

# Step 5: Pseudo-label Pakistan data
echo "ðŸ·ï¸  Step 5: Pseudo-labeling Pakistan data..."
python regional_data/pseudo_label.py

# Step 6: Train model
echo "ðŸš‚ Step 6: Training custom model..."
python training/train_custom_model.py --data merged_dataset/data.yaml --output training_output

# Step 7: Evaluate model
echo "ðŸ“Š Step 7: Evaluating model..."
python training/evaluation.py --model training_output/best.pt --data merged_dataset/data.yaml

echo "âœ… Training pipeline completed!"
EOF
    
    # Make scripts executable
    chmod +x start_flask_dev.sh
    chmod +x start_flask_prod.sh
    chmod +x run_training_pipeline.sh
    
    print_status "Startup scripts created"
}

# Create README
create_readme() {
    print_header "Creating README documentation..."
    
    cat > README.md << 'EOF'
# Advanced Multi-Dataset Object Detection System

A comprehensive YOLOv8-based object detection system trained on multiple datasets with 1500+ classes, specifically enhanced for Pakistan/South Asian objects.

## ðŸš€ Quick Start

### 1. Setup
```bash
./setup.sh
```

### 2. Start Flask Backend
```bash
./start_flask_dev.sh
```

### 3. Run Complete Training Pipeline
```bash
./run_training_pipeline.sh
```

## ðŸ“ Project Structure

```
project/
â”œâ”€â”€ data_pipeline/          # Dataset download and processing
â”œâ”€â”€ training/              # Model training and evaluation
â”œâ”€â”€ regional_data/         # Pakistan-specific data collection
â”œâ”€â”€ flask_backend/         # Enhanced Flask backend
â”œâ”€â”€ models/               # Trained models storage
â”œâ”€â”€ datasets/             # Raw datasets
â”œâ”€â”€ merged_dataset/       # Processed unified dataset
â””â”€â”€ logs/                # System logs
```

## ðŸ”§ API Endpoints

- `POST /predict` - Object detection
- `GET /model/info` - Model information
- `GET /model/classes` - Supported classes
- `POST /model/switch` - Switch model
- `GET /health` - Health check

## ðŸŽ¯ Features

- **1500+ Object Classes**: Trained on COCO, Open Images, LVIS, Objects365
- **Pakistan-Specific Objects**: 80+ regional objects (currency, food, clothing, etc.)
- **Smart Model Management**: Automatic model selection and versioning
- **Inference Caching**: Optimized for real-time performance
- **Comprehensive Evaluation**: Detailed metrics and visualizations

## ðŸ“Š Model Performance

- **mAP@0.5**: >0.5 on merged validation set
- **Inference Time**: <100ms on GPU, <500ms on CPU
- **Model Size**: <500MB for deployment
- **Classes**: 1500-2000+ unified object categories

## ðŸš€ Deployment

### Development
```bash
./start_flask_dev.sh
```

### Production
```bash
./start_flask_prod.sh
```

### Railway/Render
The system is optimized for Railway/Render deployment with automatic model management and CPU fallback.

## ðŸ“ License

MIT License - See LICENSE file for details.
EOF
    
    print_status "README created"
}

# Run health checks
run_health_checks() {
    print_header "Running health checks..."
    
    # Check if Flask can start
    print_status "Testing Flask import..."
    python3 -c "from flask import Flask; print('Flask OK')"
    
    # Check if YOLOv8 can load
    print_status "Testing YOLOv8 import..."
    python3 -c "from ultralytics import YOLO; print('YOLOv8 OK')"
    
    # Check if model manager works
    print_status "Testing model manager..."
    python3 -c "import sys; sys.path.append('flask_backend'); from model_manager import get_model_manager; print('Model Manager OK')"
    
    print_status "All health checks passed!"
}

# Main setup function
main() {
    print_header "ðŸš€ Advanced Multi-Dataset Object Detection System Setup"
    echo "This script will set up the complete system for training and deployment."
    echo ""
    
    # Run setup steps
    check_python
    check_pip
    create_venv
    install_dependencies
    create_directories
    download_models
    create_configs
    setup_git
    create_startup_scripts
    create_readme
    run_health_checks
    
    print_header "âœ… Setup completed successfully!"
    echo ""
    print_status "Next steps:"
    echo "  1. Start Flask backend: ./start_flask_dev.sh"
    echo "  2. Run training pipeline: ./run_training_pipeline.sh"
    echo "  3. Check API at: http://localhost:5000"
    echo ""
    print_status "For production deployment:"
    echo "  - Use ./start_flask_prod.sh"
    echo "  - Configure environment variables in .env"
    echo "  - Place trained models in models/ directory"
    echo ""
    print_warning "Note: Training pipeline requires significant computational resources"
    print_warning "Consider using Google Colab for training large models"
}

# Run main function
main "$@"
